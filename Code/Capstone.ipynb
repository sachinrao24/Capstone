{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660794ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip uninstall opencv-python --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10a1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d43527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gTTS\n",
    "# %pip install playsound==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62d72f",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6ab66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gtts  \n",
    "from playsound import playsound\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "PoseLandmark = mp.solutions.pose.PoseLandmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc30888",
   "metadata": {},
   "source": [
    "## Get video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b61b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     cv2.imshow('Mediapipe Feed', frame)\n",
    "    \n",
    "#     if cv2.waitKey(17) & 0xFF == ord('q'): \n",
    "#         break\n",
    "        \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609f788",
   "metadata": {},
   "source": [
    "## Display landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b566a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# ## Setup mediapipe instance\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor image to RGB\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "      \n",
    "#         # Make detection\n",
    "#         results = pose.process(image)\n",
    "    \n",
    "#         # Recolor back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # Render detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "#                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "#                                  )               \n",
    "        \n",
    "#         cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1178254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# ## Setup mediapipe instance\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor image to RGB\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "      \n",
    "#         # Make detection\n",
    "#         results = pose.process(image)\n",
    "    \n",
    "#         # Recolor back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # Extract landmarks\n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "#             print(landmarks)\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "        \n",
    "#         # Render detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "#                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "#                                  )               \n",
    "        \n",
    "#         cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118bb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lndmrk in mp_pose.PoseLandmark:\n",
    "#     print(lndmrk)\n",
    "\n",
    "\n",
    "# Ouput-\n",
    "# PoseLandmark.NOSE\n",
    "# PoseLandmark.LEFT_EYE_INNER\n",
    "# PoseLandmark.LEFT_EYE\n",
    "# PoseLandmark.LEFT_EYE_OUTER\n",
    "# PoseLandmark.RIGHT_EYE_INNER\n",
    "# PoseLandmark.RIGHT_EYE\n",
    "# PoseLandmark.RIGHT_EYE_OUTER\n",
    "# PoseLandmark.LEFT_EAR\n",
    "# PoseLandmark.RIGHT_EAR\n",
    "# PoseLandmark.MOUTH_LEFT\n",
    "# PoseLandmark.MOUTH_RIGHT\n",
    "# PoseLandmark.LEFT_SHOULDER\n",
    "# PoseLandmark.RIGHT_SHOULDER\n",
    "# PoseLandmark.LEFT_ELBOW\n",
    "# PoseLandmark.RIGHT_ELBOW\n",
    "# PoseLandmark.LEFT_WRIST\n",
    "# PoseLandmark.RIGHT_WRIST\n",
    "# PoseLandmark.LEFT_PINKY\n",
    "# PoseLandmark.RIGHT_PINKY\n",
    "# PoseLandmark.LEFT_INDEX\n",
    "# PoseLandmark.RIGHT_INDEX\n",
    "# PoseLandmark.LEFT_THUMB\n",
    "# PoseLandmark.RIGHT_THUMB\n",
    "# PoseLandmark.LEFT_HIP\n",
    "# PoseLandmark.RIGHT_HIP\n",
    "# PoseLandmark.LEFT_KNEE\n",
    "# PoseLandmark.RIGHT_KNEE\n",
    "# PoseLandmark.LEFT_ANKLE\n",
    "# PoseLandmark.RIGHT_ANKLE\n",
    "# PoseLandmark.LEFT_HEEL\n",
    "# PoseLandmark.RIGHT_HEEL\n",
    "# PoseLandmark.LEFT_FOOT_INDEX\n",
    "# PoseLandmark.RIGHT_FOOT_INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497fcb0",
   "metadata": {},
   "source": [
    "# Calculate angle between joint landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb400bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_angle(a,b,c):\n",
    "#     a = np.array(a) # First\n",
    "#     b = np.array(b) # Mid\n",
    "#     c = np.array(c) # End\n",
    "    \n",
    "#     radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "#     angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "#     if angle > 180.0:\n",
    "#         angle = 360-angle\n",
    "        \n",
    "#     return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "# elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "# wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7c9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a6e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple(np.multiply(elbow, [640, 480]).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb6a32",
   "metadata": {},
   "source": [
    "## Basic curl counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c008141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Curl counter variables\n",
    "# counter = 0 \n",
    "# stage = None\n",
    "\n",
    "# ## Setup mediapipe instance\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor image to RGB\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "      \n",
    "#         # Make detection\n",
    "#         results = pose.process(image)\n",
    "    \n",
    "#         # Recolor back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # Extract landmarks\n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "#             # Get coordinates\n",
    "#             shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "#             elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "#             wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "#             # Calculate angle\n",
    "#             angle = calculate_angle(shoulder, elbow, wrist)\n",
    "#             # Visualize angle\n",
    "#             cv2.putText(image, str(angle), \n",
    "#                            tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "#                                 )\n",
    "            \n",
    "#             # Curl counter logic\n",
    "#             if angle > 160:\n",
    "#                 stage = \"down\"\n",
    "#             if angle < 30 and stage =='down':\n",
    "#                 stage=\"up\"\n",
    "#                 counter +=1\n",
    "                       \n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "#         # Render curl counter\n",
    "#         # Setup status box\n",
    "#         cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "#         # Rep data\n",
    "#         cv2.putText(image, 'REPS', (15,12), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "#         cv2.putText(image, str(counter), \n",
    "#                     (10,60), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "#         # Stage data\n",
    "#         cv2.putText(image, 'STAGE', (65,12), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "#         cv2.putText(image, stage, \n",
    "#                     (60,60), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "#          # Render detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "#                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "#                                  )               \n",
    "        \n",
    "#         cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc11ed8",
   "metadata": {},
   "source": [
    "<h2> MediaPipe Landmarks </h2>\n",
    "<img src=\"../Media/body_landmarks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62f3d9",
   "metadata": {},
   "source": [
    "## Fixed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e825a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "webcam_dimensions = [640, 480]\n",
    "\n",
    "# Colours\n",
    "black = (0, 0, 0)\n",
    "white = (255, 255, 255)\n",
    "green = (97,250,2)\n",
    "red = (19,3,252)\n",
    "grey = (131, 133, 131)\n",
    "light_blue = (237, 215, 168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9efcf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_audio = gtts.gTTS(\"Great going\")\n",
    "hip_audio = gtts.gTTS(\"Straighten your hips more.\")\n",
    "ankle_audio = gtts.gTTS(\"Don't straighten your ankle.\")\n",
    "knee_audio = gtts.gTTS(\"Check your knee.\")\n",
    "\n",
    "correct_audio.save('correct_audio.mp3')\n",
    "hip_audio.save('hip_audio.mp3')\n",
    "ankle_audio.save('ankle_audio.mp3')\n",
    "knee_audio.save('knee_audio.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "439b6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound('./correct_audio.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450b679",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c76d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "\n",
    "def render_status_box(image, counter, stage, fontScale, form, problem):\n",
    "    cv2.rectangle(image, (0,0), (235,75), light_blue, -1)\n",
    "    cv2.rectangle(image, (300, 0), (640, 75), white, -1)\n",
    "    cv2.putText(image, 'REPS', (15,12), font, 0.5, black, 1, cv2.LINE_AA)\n",
    "    cv2.putText(image, str(counter), (10,60), font, fontScale, white, 2, cv2.LINE_AA)\n",
    "    cv2.putText(image, 'STAGE', (105,12), font, 0.5, black, 1, cv2.LINE_AA)\n",
    "    cv2.putText(image, stage, (60,60), font, 2, white, 2, cv2.LINE_AA)\n",
    "    \n",
    "    if form == \"correct\":\n",
    "        cv2.putText(image, \"Great going!\", \n",
    "                (335, 50), \n",
    "                font, 1.25, green, 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        if problem == \"hip_angle\":\n",
    "            cv2.putText(image, \"Straighten your hips more.\", \n",
    "                    (330, 45), \n",
    "                    font, 0.6, red, 2, cv2.LINE_AA)\n",
    "        elif problem == \"foot_angle\":\n",
    "            cv2.putText(image, \"Don't straighten your ankle.\", \n",
    "                    (320, 45), \n",
    "                    font, 0.6, red, 2, cv2.LINE_AA)\n",
    "        elif problem == \"knee_angle\":\n",
    "            cv2.putText(image, \"Check your knee.\", \n",
    "                    (320, 45), \n",
    "                    font, 1, red, 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69c6b6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 5, 13, 11, 25, 15, 591706)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "then = datetime.now()\n",
    "then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d223b7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 5, 13, 11, 25, 30, 259873)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d8a5be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = now-then\n",
    "sub.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93698bb6",
   "metadata": {},
   "source": [
    "# Rohan's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76e1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_coordinates = { (11, 23),\n",
    "                    (12, 24),\n",
    "                    (13, 15),\n",
    "                    (14, 16),\n",
    "                    (23, 24),\n",
    "                    (23, 25),\n",
    "                    (24, 26),\n",
    "                    (25, 27),\n",
    "                    (26, 28),\n",
    "                    (27, 31),\n",
    "                    (28, 32)}\n",
    "leg_connections = frozenset(leg_coordinates)\n",
    "\n",
    "#leg curls counter\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "form = None\n",
    "problem = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    cv2.namedWindow('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            foot = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(round(angle, 2)), \n",
    "                           tuple(np.multiply(knee, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            correctAngle = calculate_angle(shoulder, hip, knee)\n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(round(correctAngle, 2)), \n",
    "                           tuple(np.multiply(hip, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            footAngle = calculate_angle(knee, ankle, foot)\n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(round(footAngle, 2)), \n",
    "                           tuple(np.multiply(ankle, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Angle check\n",
    "            if (correctAngle > 90 and correctAngle < 130) and (footAngle > 90 and footAngle < 130):\n",
    "                form = \"correct\"\n",
    "            else:\n",
    "                form = \"incorrect\"\n",
    "                if not (correctAngle > 90 and correctAngle < 130):\n",
    "                    problem = \"hip_angle\"\n",
    "                elif not (footAngle > 90 and footAngle < 130):\n",
    "                    problem = \"foot_angle\"\n",
    "            \n",
    "            #Curl counter logic\n",
    "            if angle > 70 and angle < 110:\n",
    "                stage = \"down\"\n",
    "            if angle > 150 and angle < 180 and stage == \"down\":      \n",
    "                stage=\"up\"\n",
    "                counter +=1\n",
    "\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "         # Render detections\n",
    "        if form == \"incorrect\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, leg_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=red, thickness=2, circle_radius=2))\n",
    "            \n",
    "        elif form == \"correct\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, leg_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=green, thickness=2, circle_radius=2))\n",
    "            \n",
    "    \n",
    "        if counter < 10:\n",
    "            render_status_box(image, counter, stage, 2, form, problem)\n",
    "        else:\n",
    "            render_status_box(image, counter, stage, 1, form, problem)           \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e498069",
   "metadata": {},
   "source": [
    "# Nikita's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f064bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl_coordinates = {(11, 12),\n",
    "                    (11, 13),\n",
    "                    (11, 23),\n",
    "                    (12, 14),\n",
    "                    (12, 24),\n",
    "                    (13, 15),\n",
    "                    (14, 16),\n",
    "                    (23, 24),\n",
    "                    (23, 25),\n",
    "                    (24, 26)}\n",
    "curl_connections = frozenset(curl_coordinates)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "form = None\n",
    "problem = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    cv2.namedWindow('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            right_ear = [landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            \n",
    "            # Get coordinates\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            left_ear = [landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].x,landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            left_arm_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(round(right_hip_angle, 2)), \n",
    "                           tuple(np.multiply(right_hip_angle, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_TRIPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(left_hip_angle, 2)), \n",
    "                           tuple(np.multiply(left_hip_angle, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_TRIPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if right_hip_angle < 170 or left_hip_angle < 170:\n",
    "                form = \"incorrect\"\n",
    "                problem = \"hip_angle\"\n",
    "            else:\n",
    "                if right_arm_angle > 165 or left_arm_angle > 165:\n",
    "                    stage = \"down\"\n",
    "                    form = \"correct\"\n",
    "                elif (right_arm_angle < 30 or left_arm_angle < 30) and stage =='down':\n",
    "                    form = \"correct\"\n",
    "                    stage=\"up\"\n",
    "                    counter +=1\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "         # Render detections\n",
    "        if form == \"incorrect\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, curl_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=red, thickness=2, circle_radius=2))\n",
    "            \n",
    "        elif form == \"correct\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, curl_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=green, thickness=2, circle_radius=2))\n",
    "            \n",
    "    \n",
    "        if counter < 10:\n",
    "            render_status_box(image, counter, stage, 2, form, problem)\n",
    "        else:\n",
    "            render_status_box(image, counter, stage, 1, form, problem)  \n",
    "            \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3764b",
   "metadata": {},
   "source": [
    "# Vineet's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daa5f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "lunges_coordinates = {(11, 23),\n",
    "                      (12, 24),\n",
    "                      (23, 25),\n",
    "                      (23, 24),\n",
    "                      (25, 27),\n",
    "                      (24, 26),\n",
    "                      (26, 28)}\n",
    "lunges_connections = frozenset(lunges_coordinates)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Lunge counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "form = None\n",
    "problem = None\n",
    "\n",
    "# function to convert angles to a value easy to use for lunge logic\n",
    "def validate_angle(ang) :\n",
    "    n = (ang-170)*0.05\n",
    "    return (n >= 0 and n <= 1)\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    cv2.namedWindow('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee =  [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee =  [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            \n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            right_knee_angle = calculate_angle(right_hip,right_knee,right_ankle)\n",
    "            left_knee_angle = calculate_angle(left_hip,left_knee,left_ankle)\n",
    "            body_straight = calculate_angle(left_shoulder,left_hip,left_knee)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(round(right_knee_angle, 2)), \n",
    "                           tuple(np.multiply(right_knee, webcam_dimensions).astype(int)), \n",
    "                           font, 0.5, white, 2, cv2.LINE_AA\n",
    "                                )\n",
    "            cv2.putText(image, str(round(left_knee_angle, 2)), \n",
    "                           tuple(np.multiply(left_knee, webcam_dimensions).astype(int)), \n",
    "                           font, 0.5, white, 2, cv2.LINE_AA\n",
    "                                )\n",
    "            cv2.putText(image, str(body_straight), \n",
    "                           tuple(np.multiply(left_hip, webcam_dimensions).astype(int)), \n",
    "                           font, 0.5, white, 2, cv2.LINE_AA\n",
    "                                )\n",
    "            # Lunge counter logic\n",
    "            if (left_knee_angle > 90 and right_knee_angle < 90) or (right_knee_angle > 90 and left_knee_angle < 90):\n",
    "                stage = \"front\"\n",
    "                form = \"correct\"\n",
    "            else : \n",
    "                form = \"incorrect\"\n",
    "                problem = \"knee_angle\"\n",
    "                \n",
    "            if validate_angle(body_straight) :\n",
    "                form = \"correct\"\n",
    "                \n",
    "            if not validate_angle(left_knee_angle) and validate_angle(right_knee_angle) and stage == 'front' :\n",
    "                form = \"incorrect\"\n",
    "                problem = \"knee_angle\"\n",
    "                \n",
    "            if validate_angle(left_knee_angle) and validate_angle(right_knee_angle) and stage == 'front' :\n",
    "                stage=\"back\"\n",
    "                form = \"correct\"\n",
    "                counter +=1\n",
    "                    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "         # Render detections\n",
    "        if form == \"incorrect\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, lunges_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=red, thickness=2, circle_radius=2))\n",
    "            \n",
    "        elif form == \"correct\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, lunges_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=green, thickness=2, circle_radius=2))\n",
    "            \n",
    "    \n",
    "        if counter < 10:\n",
    "            render_status_box(image, counter, stage, 2, form, problem)\n",
    "        else:\n",
    "            render_status_box(image, counter, stage, 1, form, problem)                                           \n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a22c11",
   "metadata": {},
   "source": [
    "# Sachin's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0eedaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove unwanted landmarks\n",
    "# landmark_subset = landmark_pb2.NormalizedLandmarkList(\n",
    "#       landmark = [\n",
    "#           results.pose_landmarks.landmark[0],\n",
    "#           results.pose_landmarks.landmark[11],\n",
    "#           results.pose_landmarks.landmark[12],\n",
    "#           results.pose_landmarks.landmark[13],\n",
    "#           results.pose_landmarks.landmark[14],\n",
    "#           results.pose_landmarks.landmark[15],\n",
    "#           results.pose_landmarks.landmark[16],\n",
    "#           results.pose_landmarks.landmark[23],\n",
    "#           results.pose_landmarks.landmark[24],\n",
    "#           results.pose_landmarks.landmark[25],\n",
    "#           results.pose_landmarks.landmark[26],\n",
    "#           results.pose_landmarks.landmark[27],\n",
    "#           results.pose_landmarks.landmark[28],\n",
    "#           results.pose_landmarks.landmark[31],\n",
    "#           results.pose_landmarks.landmark[32]\n",
    "#       ]\n",
    "# )\n",
    "\n",
    "# Rendering landmarks\n",
    "# mp_drawing.draw_landmarks(image, landmark_list=landmark_subset)\n",
    "\n",
    "# poses = landmark_subset.landmark\n",
    "# for i in range(0, len(poses)-1, 2):\n",
    "#     start_idx = [\n",
    "#         poses[i].x,\n",
    "#         poses[i].y\n",
    "#     ]\n",
    "#     end_idx = [\n",
    "#         poses[i+1].x,\n",
    "#         poses[i+1].y\n",
    "#     ]\n",
    "\n",
    "#     cv2.line(image,\n",
    "#                 # here we change coordinates to fit to the camera feed\n",
    "#                 tuple(np.multiply(start_idx[:2],[640, 480]).astype(int)),\n",
    "#                 tuple(np.multiply(end_idx[:2], [640, 480]).astype(int)),\n",
    "#                 (255, 0, 0), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4654aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard set of connections\n",
    "\n",
    "# coordinates = {(11, 12),\n",
    "#               (11, 13),\n",
    "#               (11, 23),\n",
    "#               (12, 14),\n",
    "#               (12, 24),\n",
    "#               (13, 15),\n",
    "#               (14, 16),\n",
    "#               (23, 24),\n",
    "#               (23, 25),\n",
    "#               (24, 26),\n",
    "#               (25, 27),\n",
    "#               (26, 28),\n",
    "#               (27, 29),\n",
    "#               (27, 31),\n",
    "#               (28, 30),\n",
    "#               (28, 32)}\n",
    "# connections = frozenset(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fc7b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pushup_coordinates = {(11, 23),\n",
    "                       (12, 24),\n",
    "                       (23, 25),\n",
    "                       (24, 26)}\n",
    "pushup_connections = frozenset(pushup_coordinates)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Push-up counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "form = None\n",
    "problem = None\n",
    "start_time = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    cv2.namedWindow('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty('Mediapipe Feed', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angles\n",
    "            left_hip_angle = calculate_angle(left_shoulder, left_hip, left_ankle)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            \n",
    "            right_hip_angle = calculate_angle(right_shoulder, right_hip, right_ankle)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(round(left_hip_angle, 2)), \n",
    "                           tuple(np.multiply(left_hip, webcam_dimensions).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_TRIPLEX, 0.5, white, 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, str(round(right_hip_angle, 2)), \n",
    "                           tuple(np.multiply(left_hip, webcam_dimensions).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_TRIPLEX, 0.5, white, 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Form data and pushup counter logic\n",
    "            if left_hip_angle < 155 or right_hip_angle < 155:\n",
    "                form = \"incorrect\"\n",
    "                problem = \"hip_angle\"\n",
    "            elif left_hip_angle > 155 or right_hip_angle > 155:\n",
    "                form = \"correct\"\n",
    "            if left_elbow_angle < 70 or right_elbow_angle < 70:\n",
    "                stage=\"down\"\n",
    "            elif (left_elbow_angle > 160 or right_elbow_angle > 160) and stage==\"down\":\n",
    "                stage=\"up\"\n",
    "                counter+=1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        \n",
    "         # Render detections\n",
    "        if form == \"incorrect\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, pushup_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=red, thickness=2, circle_radius=2))\n",
    "            if start_time == None:\n",
    "                start_time = datetime.now()\n",
    "            else:\n",
    "                current_time = datetime.now()\n",
    "                diff = current_time - start_time\n",
    "                if diff.seconds>3:\n",
    "                    playsound('hip_audio.mp3')\n",
    "            \n",
    "        elif form == \"correct\":\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, pushup_connections,\n",
    "                                    mp_drawing.DrawingSpec(color=grey, thickness=0, circle_radius=0), \n",
    "                                    mp_drawing.DrawingSpec(color=green, thickness=2, circle_radius=2))\n",
    "            start_time = None\n",
    "            \n",
    "    \n",
    "        if counter < 10:\n",
    "            render_status_box(image, counter, stage, 2, form, problem)\n",
    "        else:\n",
    "            render_status_box(image, counter, stage, 1, form, problem)\n",
    "            \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc25b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
